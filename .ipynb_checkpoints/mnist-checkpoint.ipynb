{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, dataroot='data/mnist_26k.npz', dry_run=False, epochs=10, image_size=28, log_interval=100, lr=0.001, manual_seed=0, model='ConvNet', n_class=10, nc=1, net='', nf=[16, 32], outf='', solver='Adam', subcommand='train')\n",
      "(main) Sequential(\n",
      "  (0) Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "  (1) BatchNorm2d(num_features=16, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (2) RELU()\n",
      "  (3) Maxpool2d(kernel_size=2, stride=2)\n",
      "  (4) Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "  (5) BatchNorm2d(num_features=32, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (6) RELU()\n",
      "  (7) Maxpool2d(kernel_size=2, stride=2)\n",
      "  (8) Flatten()\n",
      "  (9) Dropout(p=0.3)\n",
      "  (10) Linear(in_features=1568, out_features=10)\n",
      ")\n",
      "==============================Training Start==============================\n",
      "000000000: #### 0 Epochs: Val Loss = 2.330e+00, Accuracy = 7.40%\n",
      "000100: Training Loss = 3.384e+00, Accuracy = 12.45%\n",
      "000200: Training Loss = 2.906e+00, Accuracy = 17.30%\n",
      "000300: Training Loss = 2.440e+00, Accuracy = 25.48%\n",
      "000000390: #### 1 Epochs: Val Loss = 1.357e+00, Accuracy = 72.81%\n",
      "000400: Training Loss = 1.995e+00, Accuracy = 36.39%\n",
      "000500: Training Loss = 1.723e+00, Accuracy = 43.30%\n",
      "000600: Training Loss = 1.460e+00, Accuracy = 50.91%\n",
      "000700: Training Loss = 1.305e+00, Accuracy = 56.27%\n",
      "000000780: #### 2 Epochs: Val Loss = 8.367e-01, Accuracy = 85.10%\n",
      "000800: Training Loss = 1.129e+00, Accuracy = 62.67%\n",
      "000900: Training Loss = 9.904e-01, Accuracy = 67.05%\n",
      "001000: Training Loss = 9.651e-01, Accuracy = 67.97%\n",
      "001100: Training Loss = 8.953e-01, Accuracy = 70.20%\n",
      "000001170: #### 3 Epochs: Val Loss = 6.296e-01, Accuracy = 89.69%\n",
      "001200: Training Loss = 8.346e-01, Accuracy = 72.53%\n",
      "001300: Training Loss = 7.782e-01, Accuracy = 74.02%\n",
      "001400: Training Loss = 7.392e-01, Accuracy = 75.94%\n",
      "001500: Training Loss = 6.850e-01, Accuracy = 78.06%\n",
      "000001560: #### 4 Epochs: Val Loss = 5.266e-01, Accuracy = 90.52%\n",
      "001600: Training Loss = 6.815e-01, Accuracy = 77.70%\n",
      "001700: Training Loss = 6.490e-01, Accuracy = 78.20%\n",
      "001800: Training Loss = 6.216e-01, Accuracy = 79.86%\n",
      "001900: Training Loss = 5.968e-01, Accuracy = 80.52%\n",
      "000001950: #### 5 Epochs: Val Loss = 4.743e-01, Accuracy = 90.83%\n",
      "002000: Training Loss = 5.639e-01, Accuracy = 81.62%\n",
      "002100: Training Loss = 5.622e-01, Accuracy = 81.45%\n",
      "002200: Training Loss = 5.383e-01, Accuracy = 82.88%\n",
      "002300: Training Loss = 5.174e-01, Accuracy = 83.00%\n",
      "000002340: #### 6 Epochs: Val Loss = 4.336e-01, Accuracy = 91.04%\n",
      "002400: Training Loss = 5.166e-01, Accuracy = 83.36%\n",
      "002500: Training Loss = 5.201e-01, Accuracy = 83.08%\n",
      "002600: Training Loss = 4.932e-01, Accuracy = 84.42%\n",
      "002700: Training Loss = 4.625e-01, Accuracy = 85.34%\n",
      "000002730: #### 7 Epochs: Val Loss = 4.213e-01, Accuracy = 90.52%\n",
      "002800: Training Loss = 4.575e-01, Accuracy = 85.11%\n",
      "002900: Training Loss = 4.626e-01, Accuracy = 85.09%\n",
      "003000: Training Loss = 4.691e-01, Accuracy = 85.08%\n",
      "003100: Training Loss = 4.481e-01, Accuracy = 85.83%\n",
      "000003120: #### 8 Epochs: Val Loss = 3.863e-01, Accuracy = 91.77%\n",
      "003200: Training Loss = 4.490e-01, Accuracy = 85.52%\n",
      "003300: Training Loss = 4.520e-01, Accuracy = 85.55%\n",
      "003400: Training Loss = 4.226e-01, Accuracy = 86.80%\n",
      "003500: Training Loss = 4.240e-01, Accuracy = 86.36%\n",
      "000003510: #### 9 Epochs: Val Loss = 3.736e-01, Accuracy = 91.46%\n",
      "003600: Training Loss = 4.198e-01, Accuracy = 86.83%\n",
      "003700: Training Loss = 4.265e-01, Accuracy = 86.47%\n",
      "003800: Training Loss = 4.146e-01, Accuracy = 86.84%\n",
      "003900: Training Loss = 4.116e-01, Accuracy = 87.08%\n",
      "000003900: #### 10 Epochs: Val Loss = 3.439e-01, Accuracy = 93.44%\n",
      "==============================Training End==============================\n"
     ]
    }
   ],
   "source": [
    "%run -i main.py --dataroot data/mnist_26k.npz --model ConvNet --nf 16 32 --nc 1  train --epochs 10 --lr 1e-3 --batch-size 64 --solver Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d6c92937dd838d4d5cad6b45cdc6deca670360475776cd4b2b4a79e3865f5ea"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
